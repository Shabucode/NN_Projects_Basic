import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple neural network
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(10, 5)  # Fully connected layer with 10 inputs and 5 outputs
        self.fc2 = nn.Linear(5, 1)   # Fully connected layer with 5 inputs and 1 output

    def forward(self, x):
        x = torch.relu(self.fc1(x))  # Apply ReLU activation function
        x = self.fc2(x)              # Output layer
        return x

# Initialize model, loss function, and optimizer
model = SimpleNN()
criterion = nn.MSELoss()  # Mean Squared Error loss for regression
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Create a random input tensor and target
input_tensor = torch.randn(10)  # Random input with 10 features
target_tensor = torch.randn(1)  # Random target value

# Training loop
for epoch in range(100):
    # Zero gradients
    optimizer.zero_grad()
    
    # Forward pass
    output = model(input_tensor)
    
    # Compute loss
    loss = criterion(output, target_tensor)
    
    # Backward pass
    loss.backward()
    
    # Update parameters
    optimizer.step()
    
    if epoch % 10 == 0:
        print(f'Epoch {epoch}: Loss = {loss.item()}')
